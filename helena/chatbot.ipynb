{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UScjCFC0O7WZ",
        "outputId": "126275f7-4fe5-467e-b22b-dbc0209eab78"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "from flask_cors import CORS\n",
        "import torch\n",
        "import json\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import threading\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, BertForTokenClassification, AutoTokenizer\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import numpy as np\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "app = Flask(__name__)\n",
        "CORS(app)\n",
        "\n",
        "intent_model = None\n",
        "ner_model = None\n",
        "tokenizer = None\n",
        "tokenizer_ner = None\n",
        "intent_labels = []\n",
        "intent_data = None\n",
        "label2id = None\n",
        "id2label = None\n",
        "semantic_model = None\n",
        "\n",
        "def load_intent(file_path):\n",
        "    intent_data = {'intents': []}\n",
        "    intent_dict = {}\n",
        "\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if line:\n",
        "            parts = line.rsplit(' ', 1)\n",
        "            if len(parts) == 2:\n",
        "                pattern, tag = parts\n",
        "                if tag not in intent_dict:\n",
        "                    intent_dict[tag] = {'tag': tag, 'patterns': [], 'responses': [f\"{tag}\"]}\n",
        "                intent_dict[tag]['patterns'].append(pattern)\n",
        "\n",
        "    intent_data['intents'] = list(intent_dict.values())\n",
        "    return intent_data\n",
        "\n",
        "def initialize_models():\n",
        "    global intent_model, ner_model, tokenizer, tokenizer_ner, intent_labels, intent_data, label2id, id2label, semantic_model\n",
        "\n",
        "    try:\n",
        "        logger.info(\"Initializing models...\")\n",
        "\n",
        "        intent_data = load_intent('intent.txt')\n",
        "\n",
        "        intent_labels = [intent['tag'] for intent in intent_data['intents']]\n",
        "        logger.info(f\"Loaded {len(intent_labels)} intent labels\")\n",
        "\n",
        "        try:\n",
        "            with open('ner_label_mapping.json', 'r', encoding='utf-8') as f:\n",
        "                ner_mapping = json.load(f)\n",
        "                label2id = ner_mapping['label2id']\n",
        "                id2label = {int(k): v for k, v in ner_mapping['id2label'].items()}\n",
        "            logger.info(\"NER label mapping loaded\")\n",
        "        except FileNotFoundError:\n",
        "            logger.warning(\"NER label mapping file not found\")\n",
        "            label2id = None\n",
        "            id2label = None\n",
        "\n",
        "        tokenizer = BertTokenizer.from_pretrained('./models/indobert-base-p2')\n",
        "        tokenizer_ner = AutoTokenizer.from_pretrained('./models/indobert-base-p2')\n",
        "\n",
        "        intent_model = BertForSequenceClassification.from_pretrained(\n",
        "            './models/indobert-base-p2',\n",
        "            num_labels=len(intent_labels)\n",
        "        )\n",
        "        intent_model.load_state_dict(torch.load('intent_model.pth', map_location='cpu'))\n",
        "        intent_model.eval()\n",
        "\n",
        "        if label2id:\n",
        "            ner_model = BertForTokenClassification.from_pretrained(\n",
        "                './models/indobert-base-p2',\n",
        "                num_labels=len(label2id),\n",
        "                id2label=id2label,\n",
        "                label2id=label2id\n",
        "            )\n",
        "            ner_model.load_state_dict(torch.load('ner_model.pth', map_location='cpu'))\n",
        "            ner_model.eval()\n",
        "            logger.info(\"NER model loaded\")\n",
        "        else:\n",
        "            ner_model = None\n",
        "            \n",
        "        logger.info(\"Loading semantic similarity model...\")\n",
        "        semantic_model = SentenceTransformer('./models/indobert-base-p2-sts-arxiv-id')\n",
        "        semantic_model.eval()\n",
        "        logger.info(\"Semantic model loaded\")\n",
        "\n",
        "        logger.info(\"All models loaded successfully\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Failed to load models: {str(e)}\")\n",
        "        return False\n",
        "\n",
        "def predict_intent(text):\n",
        "    try:\n",
        "        encoding = tokenizer(text, truncation=True, padding='max_length', max_length=128, return_tensors='pt')\n",
        "        with torch.no_grad():\n",
        "            outputs = intent_model(**encoding)\n",
        "            probs = torch.softmax(outputs.logits, dim=-1)\n",
        "            max_prob = torch.max(probs).item()\n",
        "            pred = torch.argmax(outputs.logits, dim=1)\n",
        "            predicted_intent = intent_labels[pred.item()]\n",
        "\n",
        "            if max_prob < 0.8:\n",
        "                return 'fallback', max_prob  \n",
        "            else:\n",
        "                return predicted_intent, max_prob  \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Intent prediction error: {str(e)}\")\n",
        "        return \"fallback\", 0.0\n",
        "\n",
        "def predict_ner(text):\n",
        "    if not ner_model:\n",
        "        return []\n",
        "\n",
        "    try:\n",
        "        tokens = text.split()\n",
        "        encoding = tokenizer_ner(tokens, is_split_into_words=True, return_tensors='pt', truncation=True, padding='max_length', max_length=128)\n",
        "        with torch.no_grad():\n",
        "            outputs = ner_model(**encoding)\n",
        "            logits = outputs.logits\n",
        "            preds = torch.argmax(logits, dim=-1).cpu().numpy()[0]\n",
        "\n",
        "        word_ids = encoding.word_ids(batch_index=0)\n",
        "        result = []\n",
        "        seen_word_idx = set()\n",
        "        for idx, word_idx in enumerate(word_ids):\n",
        "            if word_idx is not None and word_idx not in seen_word_idx and word_idx < len(tokens):\n",
        "                label = id2label[preds[idx]]\n",
        "                result.append((tokens[word_idx], label))\n",
        "                seen_word_idx.add(word_idx)\n",
        "        return result\n",
        "    except Exception as e:\n",
        "        logger.error(f\"NER prediction error: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "def extract_entities(ner_result):\n",
        "    entities = {}\n",
        "    current_entity = None\n",
        "    current_tokens = []\n",
        "    prev_token = None\n",
        "\n",
        "    for token, label in ner_result:\n",
        "        if token == prev_token and label.startswith(\"I-\"):\n",
        "            continue\n",
        "\n",
        "        if label.startswith('B-'):\n",
        "            if current_entity and current_tokens:\n",
        "                ent_type = current_entity[2:]\n",
        "                entities.setdefault(ent_type, []).append(' '.join(current_tokens))\n",
        "            current_entity = label\n",
        "            current_tokens = [token]\n",
        "        elif label.startswith('I-'):\n",
        "            if current_entity and current_entity[2:] == label[2:]:\n",
        "                current_tokens.append(token)\n",
        "            else:\n",
        "                if current_entity and current_tokens:\n",
        "                    ent_type = current_entity[2:]\n",
        "                    entities.setdefault(ent_type, []).append(' '.join(current_tokens))\n",
        "                current_entity = 'B-' + label[2:]\n",
        "                current_tokens = [token]\n",
        "        else:\n",
        "            if current_entity and current_tokens:\n",
        "                ent_type = current_entity[2:]\n",
        "                entities.setdefault(ent_type, []).append(' '.join(current_tokens))\n",
        "            current_entity = None\n",
        "            current_tokens = []\n",
        "\n",
        "        prev_token = token\n",
        "\n",
        "    if current_entity and current_tokens:\n",
        "        ent_type = current_entity[2:]\n",
        "        entities.setdefault(ent_type, []).append(' '.join(current_tokens))\n",
        "\n",
        "    return entities\n",
        "\n",
        "def generate_response(intent, entities=None):\n",
        "    try:\n",
        "        for item in intent_data['intents']:\n",
        "            if item['tag'] == intent:\n",
        "                response = item['responses'][0]\n",
        "                if entities:\n",
        "                    for key, values in entities.items():\n",
        "                        value = values[0] if isinstance(values, list) else values\n",
        "                        response = response.replace(f'{{{key}}}', value)\n",
        "                return response\n",
        "        return \"Maaf, saya tidak mengerti pertanyaan Anda.\"\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error generating response: {str(e)}\")\n",
        "        return \"Maaf, terjadi kesalahan.\"\n",
        "\n",
        "@app.route('/health', methods=['GET'])\n",
        "def health():\n",
        "    return jsonify({\n",
        "        'status': 'OK',\n",
        "        'message': 'Chatbot API is running',\n",
        "        'timestamp': datetime.now().isoformat(),\n",
        "        'models_loaded': {\n",
        "            'intent': intent_model is not None,\n",
        "            'ner': ner_model is not None\n",
        "        }\n",
        "    })\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        if not request.is_json:\n",
        "            return jsonify({'error': 'Request must be JSON', 'status': 'error'}), 400\n",
        "        data = request.get_json()\n",
        "        text = data.get('text', '').strip()\n",
        "\n",
        "        if not text:\n",
        "            return jsonify({'error': 'Text cannot be empty', 'status': 'error'}), 400\n",
        "\n",
        "        logger.info(f\"Input text: {text}\")\n",
        "\n",
        "        intent, confidence = predict_intent(text)\n",
        "        logger.info(f\"Predicted intent: {intent}\")\n",
        "\n",
        "        ner_result = predict_ner(text)\n",
        "        logger.info(f\"Raw NER: {ner_result}\")\n",
        "\n",
        "        entities = extract_entities(ner_result)\n",
        "        logger.info(f\"Extracted entities: {entities}\")\n",
        "\n",
        "        response = generate_response(intent, entities)\n",
        "\n",
        "        result = {\n",
        "            'intent': intent,\n",
        "            'confidence': confidence,  \n",
        "            'entities': entities,\n",
        "            'ner_tokens': ner_result,\n",
        "            'response': response,\n",
        "            'status': 'success',\n",
        "            'timestamp': datetime.now().isoformat()\n",
        "        }\n",
        "        return jsonify(result)\n",
        "\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Server error: {str(e)}\")\n",
        "        return jsonify({'error': 'Internal server error', 'details': str(e), 'status': 'error'}), 500\n",
        "\n",
        "@app.route('/semantic-search', methods=['POST'])\n",
        "def semantic_search():\n",
        "    try:\n",
        "        if not request.is_json:\n",
        "            return jsonify({'error': 'Request must be JSON'}), 400\n",
        "        \n",
        "        data = request.get_json()\n",
        "        query = data.get('query', '').strip()\n",
        "        items = data.get('items', [])\n",
        "        threshold = data.get('threshold', 0.5)\n",
        "        top_k = data.get('top_k', 5)\n",
        "        \n",
        "        if not query or not items:\n",
        "            return jsonify({'error': 'Query and items required'}), 400\n",
        "        \n",
        "        if semantic_model is None:\n",
        "            logger.error(\"Semantic model not loaded\")\n",
        "            return jsonify({'error': 'Semantic model not initialized'}), 500\n",
        "        \n",
        "        logger.info(f\"Semantic search for: {query} among {len(items)} items\")\n",
        "        \n",
        "        query_emb = semantic_model.encode(query, convert_to_tensor=True, normalize_embeddings=True)\n",
        "        item_embeddings = semantic_model.encode(items, convert_to_tensor=True, normalize_embeddings=True)\n",
        "        \n",
        "        cosine_scores = util.cos_sim(query_emb, item_embeddings)[0]\n",
        "        \n",
        "        all_scores = [(i, float(score)) for i, score in enumerate(cosine_scores)]\n",
        "        all_scores.sort(key=lambda x: x[1], reverse=True)\n",
        "        \n",
        "        results = []\n",
        "        for idx, score in all_scores[:top_k]:\n",
        "            if score >= threshold:\n",
        "                results.append({\n",
        "                    'nama': items[idx],\n",
        "                    'score': score\n",
        "                })\n",
        "        \n",
        "        logger.info(f\"Found {len(results)} semantic matches above {threshold}\")\n",
        "        return jsonify({\n",
        "            'status': 'success',\n",
        "            'results': results,\n",
        "            'query': query\n",
        "        })\n",
        "        \n",
        "    except Exception as e:\n",
        "        logger.error(f\"Semantic search error: {str(e)}\", exc_info=True)\n",
        "        return jsonify({'error': str(e), 'status': 'error'}), 500\n",
        "\n",
        "@app.route('/test', methods=['GET'])\n",
        "def test():\n",
        "    return jsonify({'message': 'API is working!', 'timestamp': datetime.now().isoformat()})\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    if initialize_models():\n",
        "        app.run(host='0.0.0.0', port=5000)\n",
        "    else:\n",
        "        logger.error(\"Server not started due to model loading failure\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0260038a51af436c8d5f9e98feab9ac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f26b9162fe4413fbf272bd98d5e0648",
              "IPY_MODEL_e38b9cf49d2342e4ac9f4aaca7e6695f",
              "IPY_MODEL_33162ee9303d462786f72b8331a702f8"
            ],
            "layout": "IPY_MODEL_d31e331f1a9b4566bf2bc88a8dad6898"
          }
        },
        "33162ee9303d462786f72b8331a702f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dae5483962f34d7da131e210ce901025",
            "placeholder": "​",
            "style": "IPY_MODEL_5a3da1e9282f4719b7ba0b135a7392f9",
            "value": " 498M/498M [00:01&lt;00:00, 255MB/s]"
          }
        },
        "41788f9d3ef94183ad588d51918786c9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a3da1e9282f4719b7ba0b135a7392f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f26b9162fe4413fbf272bd98d5e0648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a79637f3a56e4f07a25f7510d3bd3453",
            "placeholder": "​",
            "style": "IPY_MODEL_bfcae6079fdf4f3585bd782d41ef508b",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "7dbe71abc6b84ae68f587a52aa694955": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a79637f3a56e4f07a25f7510d3bd3453": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfcae6079fdf4f3585bd782d41ef508b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d31e331f1a9b4566bf2bc88a8dad6898": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dae5483962f34d7da131e210ce901025": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e38b9cf49d2342e4ac9f4aaca7e6695f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41788f9d3ef94183ad588d51918786c9",
            "max": 497810400,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dbe71abc6b84ae68f587a52aa694955",
            "value": 497810400
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
